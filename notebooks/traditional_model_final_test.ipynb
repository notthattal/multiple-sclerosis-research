{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn.utils import spectral_norm\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy import signal\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, X, y, session_ids, metadata, window_size=3):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.metadata = metadata\n",
    "        self.session_ids = session_ids\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # Group data by session\n",
    "        session_groups = {}\n",
    "        for idx, session_id in enumerate(session_ids):\n",
    "            session_groups.setdefault(session_id, []).append((X[idx], y[idx]))\n",
    "\n",
    "        # Create sliding windows within each session\n",
    "        for session_id, session_data in session_groups.items():\n",
    "            for i in range(len(session_data) - window_size + 1):\n",
    "                steps = [data[0] for data in session_data[i:i+window_size]]\n",
    "                window_X = np.vstack(steps)\n",
    "                window_y = session_data[i+window_size-1][1]\n",
    "                self.X.append(window_X)\n",
    "                self.y.append(window_y)\n",
    "\n",
    "        # Now extract features for all windows, then append duration\n",
    "        self.X, self.y = self.extract_features()\n",
    "    \n",
    "    def extract_features(self):\n",
    "        features = []\n",
    "        labels = []\n",
    "        for i in range(len(self.X)):\n",
    "            X_win, y_val = self.X[i], self.y[i]\n",
    "            sequence_features = []\n",
    "            # Compute basic statistical features for each sensor\n",
    "            for j in range(X_win.shape[1]):\n",
    "                sensor_data = X_win[:, j]\n",
    "                freqs, psd = signal.welch(sensor_data, fs=100)\n",
    "                sequence_features.extend([\n",
    "                    np.mean(sensor_data),\n",
    "                    np.std(sensor_data),\n",
    "                    np.min(sensor_data),\n",
    "                    np.max(sensor_data),\n",
    "                    np.median(sensor_data),\n",
    "                    stats.skew(sensor_data),\n",
    "                    stats.kurtosis(sensor_data),\n",
    "                    np.percentile(sensor_data, 25),\n",
    "                    np.percentile(sensor_data, 75),\n",
    "                    np.ptp(sensor_data),\n",
    "                    np.sum(psd),\n",
    "                    np.mean(psd),\n",
    "                    np.max(psd),\n",
    "                    freqs[np.argmax(psd)]\n",
    "                ])\n",
    "            # Compute trend and dynamics features for each sensor\n",
    "            for j in range(X_win.shape[1]):\n",
    "                sensor_data = X_win[:, j]\n",
    "                if len(sensor_data) > 5:\n",
    "                    detrended = signal.detrend(sensor_data)\n",
    "                    trend = sensor_data - detrended\n",
    "                    sequence_features.append(np.mean(trend))\n",
    "                    first_diff = np.diff(sensor_data)\n",
    "                    sequence_features.extend([\n",
    "                        np.mean(np.abs(first_diff)),\n",
    "                        np.std(first_diff)\n",
    "                    ])\n",
    "                    if len(first_diff) > 1:\n",
    "                        second_diff = np.diff(first_diff)\n",
    "                        sequence_features.append(np.mean(np.abs(second_diff)))\n",
    "            features.append(sequence_features)\n",
    "            labels.append(y_val.item())\n",
    "        \n",
    "        # Append the session-level duration as a new feature for all samples\n",
    "        features = self.add_mean_duration_feature(features)\n",
    "        return np.array(features), np.array(labels)\n",
    "    \n",
    "    def add_mean_duration_feature(self, X_features):\n",
    "        # Use the same number of session_ids as there are samples\n",
    "        session_ids = self.session_ids[:len(X_features)]\n",
    "        mean_durations = np.zeros(len(X_features))\n",
    "        for session_id in np.unique(session_ids):\n",
    "            session_mask = session_ids == session_id\n",
    "            session_duration = self.metadata.loc[self.metadata['session_id'] == session_id, 'duration'].mean()\n",
    "            mean_durations[session_mask] = session_duration\n",
    "        mean_durations = mean_durations.reshape(-1, 1)\n",
    "        return np.hstack((X_features, mean_durations))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = np.load('sensor_data.npy')  # Shape: (num_steps, time_steps, num_sensors)\n",
    "metadata = pd.read_csv('combined_metadata.csv')\n",
    "y = metadata['has_ms'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by session for sequence integrity while stratifying\n",
    "sessions = metadata['session_id'].values\n",
    "unique_sessions = np.unique(sessions)\n",
    "\n",
    "# Create a mapping of session_id to MS status\n",
    "session_to_ms_status = {}\n",
    "for session_id in unique_sessions:\n",
    "    # Get all rows for this session\n",
    "    session_mask = metadata['session_id'] == session_id\n",
    "    # If any row has MS, the whole session is labeled as MS\n",
    "    has_ms = any(metadata.loc[session_mask, 'has_ms'] == 1)\n",
    "    session_to_ms_status[session_id] = 1 if has_ms else 0\n",
    "\n",
    "# Create lists of session IDs by MS status\n",
    "ms_sessions = [s for s, status in session_to_ms_status.items() if status == 1]\n",
    "non_ms_sessions = [s for s, status in session_to_ms_status.items() if status == 0]\n",
    "\n",
    "# Perform stratified split on MS and non-MS sessions separately\n",
    "train_ms, temp_ms = train_test_split(ms_sessions, test_size=0.3, random_state=42, shuffle=True)\n",
    "train_non_ms, temp_non_ms = train_test_split(non_ms_sessions, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# Further split temp sets into validation and test\n",
    "val_ms, test_ms = train_test_split(temp_ms, test_size=0.5, random_state=42, shuffle=True)\n",
    "val_non_ms, test_non_ms = train_test_split(temp_non_ms, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "# Combine MS and non-MS sessions for each split\n",
    "train_sessions = train_ms + train_non_ms\n",
    "val_sessions = val_ms + val_non_ms\n",
    "test_sessions = test_ms + test_non_ms\n",
    "\n",
    "train_indices = metadata['session_id'].isin(train_sessions)\n",
    "val_indices = metadata['session_id'].isin(val_sessions)\n",
    "test_indices = metadata['session_id'].isin(test_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m window_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Create datasets\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_sessions_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m SensorDataset(X_val, y_val, val_sessions_ids, metadata, window_size\u001b[38;5;241m=\u001b[39mwindow_size)\n\u001b[1;32m     23\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m SensorDataset(X_test, y_test, test_sessions_ids, metadata, window_size\u001b[38;5;241m=\u001b[39mwindow_size)\n",
      "Cell \u001b[0;32mIn[7], line 24\u001b[0m, in \u001b[0;36mSensorDataset.__init__\u001b[0;34m(self, X, y, session_ids, metadata, window_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mappend(window_y)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Now extract features for all windows, then append duration\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m, in \u001b[0;36mSensorDataset.extract_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m     sensor_data \u001b[38;5;241m=\u001b[39m X_win[:, j]\n\u001b[1;32m     35\u001b[0m     freqs, psd \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mwelch(sensor_data, fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     36\u001b[0m     sequence_features\u001b[38;5;241m.\u001b[39mextend([\n\u001b[1;32m     37\u001b[0m         np\u001b[38;5;241m.\u001b[39mmean(sensor_data),\n\u001b[1;32m     38\u001b[0m         np\u001b[38;5;241m.\u001b[39mstd(sensor_data),\n\u001b[1;32m     39\u001b[0m         np\u001b[38;5;241m.\u001b[39mmin(sensor_data),\n\u001b[1;32m     40\u001b[0m         np\u001b[38;5;241m.\u001b[39mmax(sensor_data),\n\u001b[1;32m     41\u001b[0m         np\u001b[38;5;241m.\u001b[39mmedian(sensor_data),\n\u001b[1;32m     42\u001b[0m         stats\u001b[38;5;241m.\u001b[39mskew(sensor_data),\n\u001b[0;32m---> 43\u001b[0m         \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkurtosis\u001b[49m\u001b[43m(\u001b[49m\u001b[43msensor_data\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     44\u001b[0m         np\u001b[38;5;241m.\u001b[39mpercentile(sensor_data, \u001b[38;5;241m25\u001b[39m),\n\u001b[1;32m     45\u001b[0m         np\u001b[38;5;241m.\u001b[39mpercentile(sensor_data, \u001b[38;5;241m75\u001b[39m),\n\u001b[1;32m     46\u001b[0m         np\u001b[38;5;241m.\u001b[39mptp(sensor_data),\n\u001b[1;32m     47\u001b[0m         np\u001b[38;5;241m.\u001b[39msum(psd),\n\u001b[1;32m     48\u001b[0m         np\u001b[38;5;241m.\u001b[39mmean(psd),\n\u001b[1;32m     49\u001b[0m         np\u001b[38;5;241m.\u001b[39mmax(psd),\n\u001b[1;32m     50\u001b[0m         freqs[np\u001b[38;5;241m.\u001b[39margmax(psd)]\n\u001b[1;32m     51\u001b[0m     ])\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Compute trend and dynamics features for each sensor\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_win\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n",
      "File \u001b[0;32m~/Documents/AIPI_549/FinalProject/multiple-sclerosis-research/venv/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:483\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    481\u001b[0m     samples \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(sample\u001b[38;5;241m.\u001b[39mravel()) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples]\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 483\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m     axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(axis)\n\u001b[1;32m    485\u001b[0m     n_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis)\n",
      "File \u001b[0;32m~/Documents/AIPI_549/FinalProject/multiple-sclerosis-research/venv/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:18\u001b[0m, in \u001b[0;36m_broadcast_arrays\u001b[0;34m(arrays, axis)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_broadcast_arrays\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Broadcast shapes of arrays, ignoring incompatibility of specified axes\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     new_shapes \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_array_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m         new_shapes \u001b[38;5;241m=\u001b[39m [new_shapes]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(arrays)\n",
      "File \u001b[0;32m~/Documents/AIPI_549/FinalProject/multiple-sclerosis-research/venv/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:30\u001b[0m, in \u001b[0;36m_broadcast_array_shapes\u001b[0;34m(arrays, axis)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mBroadcast shapes of arrays, ignoring incompatibility of specified axes\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m shapes \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(arr)\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIPI_549/FinalProject/multiple-sclerosis-research/venv/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:80\u001b[0m, in \u001b[0;36m_broadcast_shapes\u001b[0;34m(shapes, axis)\u001b[0m\n\u001b[1;32m     75\u001b[0m new_shape \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m new_shapes\u001b[38;5;241m.\u001b[39mall(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Among all arrays, there can only be one unique non-1 shape element.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Therefore, if any non-1 shape element does not match what we found\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# above, the arrays must not be broadcastable after all.\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(\u001b[38;5;241m~\u001b[39m((new_shapes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m|\u001b[39m (\u001b[43mnew_shapes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m))):\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray shapes are incompatible for broadcasting.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# Add back the shape elements that were ignored\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Downsample X to have 10 timesteps instead of 100\n",
    "X = X_original.copy()#reshape(X_original.shape[0], 25, -1, X_original.shape[2]).mean(axis=2)\n",
    "\n",
    "X_train, X_val, X_test = X[train_indices], X[val_indices], X[test_indices]\n",
    "y_train, y_val, y_test = y[train_indices], y[val_indices], y[test_indices]\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X.shape[2])).reshape(X_train.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X.shape[2])).reshape(X_val.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X.shape[2])).reshape(X_test.shape)\n",
    "\n",
    "# Session IDs for reference\n",
    "train_sessions_ids = sessions[train_indices]\n",
    "val_sessions_ids = sessions[val_indices]\n",
    "test_sessions_ids = sessions[test_indices]\n",
    "\n",
    "window_size = 4\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SensorDataset(X_train, y_train, train_sessions_ids, metadata, window_size=window_size)\n",
    "val_dataset = SensorDataset(X_val, y_val, val_sessions_ids, metadata, window_size=window_size)\n",
    "test_dataset = SensorDataset(X_test, y_test, test_sessions_ids, metadata, window_size=window_size)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features, y_train = train_dataset.X, train_dataset.y\n",
    "X_val_features, y_val = val_dataset.X, val_dataset.y\n",
    "X_test_features, y_test = test_dataset.X, test_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9519\n",
      "Precision: 0.9020\n",
      "Recall: 0.9604\n",
      "F1 Score: 0.9303\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1509\n",
      "           1       0.90      0.96      0.93       757\n",
      "\n",
      "    accuracy                           0.95      2266\n",
      "   macro avg       0.94      0.95      0.95      2266\n",
      "weighted avg       0.95      0.95      0.95      2266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_combined = np.vstack((X_train_features, X_val_features))\n",
    "y_combined = np.concatenate((y_train, y_val))\n",
    "\n",
    "# Best parameters: {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1.0}\n",
    "optimized_gb = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=5,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "optimized_gb.fit(X_combined, y_combined)\n",
    "y_test_pred = optimized_gb.predict(X_test_features)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GB Regular CV:\n",
    "Accuracy: 0.8883 ± 0.0505\n",
    "Precision: 0.8854 ± 0.0345\n",
    "Recall: 0.7929 ± 0.1382\n",
    "F1 Score: 0.8308 ± 0.0894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 'optimized_gb_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "with open('optimized_gb_model.pkl', 'wb') as file:\n",
    "    pickle.dump(optimized_gb, file)\n",
    "\n",
    "print(\"Model saved to 'optimized_gb_model2.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9629\n",
      "Ensemble Precision: 0.9170\n",
      "Ensemble Recall: 0.9775\n",
      "Ensemble F1 Score: 0.9463\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      1509\n",
      "           1       0.92      0.98      0.95       757\n",
      "\n",
      "    accuracy                           0.96      2266\n",
      "   macro avg       0.95      0.97      0.96      2266\n",
      "weighted avg       0.96      0.96      0.96      2266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Combine training and validation sets\n",
    "X_combined = np.vstack((X_train_features, X_val_features))\n",
    "y_combined = np.concatenate((y_train, y_val))\n",
    "\n",
    "# Define the base estimator with your tuned parameters\n",
    "base_gb = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=3,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create an ensemble of multiple instances of your GradientBoostingClassifier\n",
    "ensemble_gb = BaggingClassifier(\n",
    "    estimator=base_gb,\n",
    "    n_estimators=5,          # number of copies\n",
    "    max_samples=0.8,         # each model trains on 80% of the combined data (bootstrapped)\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the ensemble on the combined training set\n",
    "ensemble_gb.fit(X_combined, y_combined)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = ensemble_gb.predict(X_test_features)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Ensemble Precision: {precision:.4f}\")\n",
    "print(f\"Ensemble Recall: {recall:.4f}\")\n",
    "print(f\"Ensemble F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import get_train_test_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.mps.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def evaluate_traditional_model(model, test_dataset):\n",
    "    X_test, y_test = test_dataset.X, test_dataset.y\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred)\n",
    "    recall = recall_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "def save_model(model, output_path):\n",
    "    with open(output_path, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    print(f\"Model saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('sensor_data.npy')\n",
    "metadata = pd.read_csv('combined_metadata.csv')\n",
    "y = metadata['has_ms'].values\n",
    "\n",
    "train_dataset, test_dataset, scaler = get_train_test_datasets(X, y, metadata, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9541\n",
      "Precision: 0.9568\n",
      "Recall: 0.9061\n",
      "F1 Score: 0.9307\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      1937\n",
      "           1       0.96      0.91      0.93      1001\n",
      "\n",
      "    accuracy                           0.95      2938\n",
      "   macro avg       0.95      0.94      0.95      2938\n",
      "weighted avg       0.95      0.95      0.95      2938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_traditional_model(train_dataset, test_dataset=None, save_path=''):\n",
    "    X_train, y_train = train_dataset.X, train_dataset.y\n",
    "\n",
    "    base_gb = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.2,\n",
    "        max_depth=3,\n",
    "        min_samples_split=2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Create an ensemble of multiple instances of your GradientBoostingClassifier\n",
    "    ensemble_gb = BaggingClassifier(\n",
    "        estimator=base_gb,\n",
    "        n_estimators=5,\n",
    "        max_samples=0.9,\n",
    "        bootstrap=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train the ensemble on the training set\n",
    "    ensemble_gb.fit(X_train, y_train)\n",
    "\n",
    "    if test_dataset:\n",
    "        evaluate_traditional_model(ensemble_gb, test_dataset)\n",
    "\n",
    "    if save_path != '':\n",
    "        save_model(ensemble_gb, save_path)\n",
    "\n",
    "    return ensemble_gb\n",
    "\n",
    "model = train_traditional_model(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import prep_collection_for_inference\n",
    "\n",
    "print(prep_collection_for_inference('./data/test', scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(gb, param_grid, cv=3, n_jobs=-1)\n",
    "grid.fit(train_dataset.X, train_dataset.y)\n",
    "best_gb = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFECV(cv=5,\n",
       "      estimator=GradientBoostingClassifier(learning_rate=0.2, random_state=42),\n",
       "      n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RFECV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_selection.RFECV.html\">?<span>Documentation for RFECV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RFECV(cv=5,\n",
       "      estimator=GradientBoostingClassifier(learning_rate=0.2, random_state=42),\n",
       "      n_jobs=-1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: GradientBoostingClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(learning_rate=0.2, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">?<span>Documentation for GradientBoostingClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingClassifier(learning_rate=0.2, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFECV(cv=5,\n",
       "      estimator=GradientBoostingClassifier(learning_rate=0.2, random_state=42),\n",
       "      n_jobs=-1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.2,\n",
    "        max_depth=3,\n",
    "        min_samples_split=2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "selector = RFECV(estimator=gb, step=1, cv=5, n_jobs=-1)\n",
    "selector.fit(train_dataset.X, train_dataset.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selector.ranking_\n",
    "\n",
    "[97,  1,  2, 13, 36, 67,  1, 22,  9,  1, 57,  8, 34, 72, 84, 17, 43,\n",
    "    7, 66, 14,  1,  1, 19, 46, 74, 65, 85, 33, 51,  1, 55, 29, 32, 87,\n",
    "    1,  1,  1,  1, 93, 94, 90, 95, 40,  1, 41, 49, 39, 35,  1,  1,  1,\n",
    "    25, 24, 81, 54, 92, 96,  1, 18, 45, 37, 77,  1,  1,  1,  1, 91, 89,\n",
    "    53, 70, 83,  6, 15, 38, 44, 23,  1,  1,  1, 16, 88, 86, 52, 61, 63,\n",
    "    1, 27, 62, 20, 21,  1,  1, 12,  3, 58, 71, 64, 50, 82,  5, 10,  1,\n",
    "    73, 75, 28, 78, 80, 11, 26, 60, 68,  1, 31,  1, 56, 69,  4, 30, 79,\n",
    "    1, 59, 47, 76, 48,  1, 42,  1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([97,  1,  2, 13, 36, 67,  1, 22,  9,  1, 57,  8, 34, 72, 84, 17, 43,\n",
       "        7, 66, 14,  1,  1, 19, 46, 74, 65, 85, 33, 51,  1, 55, 29, 32, 87,\n",
       "        1,  1,  1,  1, 93, 94, 90, 95, 40,  1, 41, 49, 39, 35,  1,  1,  1,\n",
       "       25, 24, 81, 54, 92, 96,  1, 18, 45, 37, 77,  1,  1,  1,  1, 91, 89,\n",
       "       53, 70, 83,  6, 15, 38, 44, 23,  1,  1,  1, 16, 88, 86, 52, 61, 63,\n",
       "        1, 27, 62, 20, 21,  1,  1, 12,  3, 58, 71, 64, 50, 82,  5, 10,  1,\n",
       "       73, 75, 28, 78, 80, 11, 26, 60, 68,  1, 31,  1, 56, 69,  4, 30, 79,\n",
       "        1, 59, 47, 76, 48,  1, 42,  1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selector.support:\n",
    "\n",
    "[False,  True, False, False, False, False,  True, False, False,\n",
    "    True, False, False, False, False, False, False, False, False,\n",
    "    False, False,  True,  True, False, False, False, False, False,\n",
    "    False, False,  True, False, False, False, False,  True,  True,\n",
    "    True,  True, False, False, False, False, False,  True, False,\n",
    "    False, False, False,  True,  True,  True, False, False, False,\n",
    "    False, False, False,  True, False, False, False, False,  True,\n",
    "    True,  True,  True, False, False, False, False, False, False,\n",
    "    False, False, False, False,  True,  True,  True, False, False,\n",
    "    False, False, False, False,  True, False, False, False, False,\n",
    "    True,  True, False, False, False, False, False, False, False,\n",
    "    False, False,  True, False, False, False, False, False, False,\n",
    "    False, False, False,  True, False,  True, False, False, False,\n",
    "    False, False,  True, False, False, False, False,  True, False,\n",
    "    True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False,  True,  True,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "       False, False, False,  True,  True,  True, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False,  True,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True,  True,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "        True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature index 0: sensor_0_mean, Ranking: 97, Selected: False\n",
      "Feature index 1: sensor_0_std, Ranking: 1, Selected: True\n",
      "Feature index 2: sensor_0_min, Ranking: 2, Selected: False\n",
      "Feature index 3: sensor_0_max, Ranking: 13, Selected: False\n",
      "Feature index 4: sensor_0_median, Ranking: 36, Selected: False\n",
      "Feature index 5: sensor_0_skew, Ranking: 67, Selected: False\n",
      "Feature index 6: sensor_0_kurtosis, Ranking: 1, Selected: True\n",
      "Feature index 7: sensor_0_25th_percentile, Ranking: 22, Selected: False\n",
      "Feature index 8: sensor_0_75th_percentile, Ranking: 9, Selected: False\n",
      "Feature index 9: sensor_0_ptp, Ranking: 1, Selected: True\n",
      "Feature index 10: sensor_0_sum_psd, Ranking: 57, Selected: False\n",
      "Feature index 11: sensor_0_mean_psd, Ranking: 8, Selected: False\n",
      "Feature index 12: sensor_0_max_psd, Ranking: 34, Selected: False\n",
      "Feature index 13: sensor_0_freq_at_max_psd, Ranking: 72, Selected: False\n",
      "Feature index 14: sensor_1_mean, Ranking: 84, Selected: False\n",
      "Feature index 15: sensor_1_std, Ranking: 17, Selected: False\n",
      "Feature index 16: sensor_1_min, Ranking: 43, Selected: False\n",
      "Feature index 17: sensor_1_max, Ranking: 7, Selected: False\n",
      "Feature index 18: sensor_1_median, Ranking: 66, Selected: False\n",
      "Feature index 19: sensor_1_skew, Ranking: 14, Selected: False\n",
      "Feature index 20: sensor_1_kurtosis, Ranking: 1, Selected: True\n",
      "Feature index 21: sensor_1_25th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 22: sensor_1_75th_percentile, Ranking: 19, Selected: False\n",
      "Feature index 23: sensor_1_ptp, Ranking: 46, Selected: False\n",
      "Feature index 24: sensor_1_sum_psd, Ranking: 74, Selected: False\n",
      "Feature index 25: sensor_1_mean_psd, Ranking: 65, Selected: False\n",
      "Feature index 26: sensor_1_max_psd, Ranking: 85, Selected: False\n",
      "Feature index 27: sensor_1_freq_at_max_psd, Ranking: 33, Selected: False\n",
      "Feature index 28: sensor_2_mean, Ranking: 51, Selected: False\n",
      "Feature index 29: sensor_2_std, Ranking: 1, Selected: True\n",
      "Feature index 30: sensor_2_min, Ranking: 55, Selected: False\n",
      "Feature index 31: sensor_2_max, Ranking: 29, Selected: False\n",
      "Feature index 32: sensor_2_median, Ranking: 32, Selected: False\n",
      "Feature index 33: sensor_2_skew, Ranking: 87, Selected: False\n",
      "Feature index 34: sensor_2_kurtosis, Ranking: 1, Selected: True\n",
      "Feature index 35: sensor_2_25th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 36: sensor_2_75th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 37: sensor_2_ptp, Ranking: 1, Selected: True\n",
      "Feature index 38: sensor_2_sum_psd, Ranking: 93, Selected: False\n",
      "Feature index 39: sensor_2_mean_psd, Ranking: 94, Selected: False\n",
      "Feature index 40: sensor_2_max_psd, Ranking: 90, Selected: False\n",
      "Feature index 41: sensor_2_freq_at_max_psd, Ranking: 95, Selected: False\n",
      "Feature index 42: sensor_3_mean, Ranking: 40, Selected: False\n",
      "Feature index 43: sensor_3_std, Ranking: 1, Selected: True\n",
      "Feature index 44: sensor_3_min, Ranking: 41, Selected: False\n",
      "Feature index 45: sensor_3_max, Ranking: 49, Selected: False\n",
      "Feature index 46: sensor_3_median, Ranking: 39, Selected: False\n",
      "Feature index 47: sensor_3_skew, Ranking: 35, Selected: False\n",
      "Feature index 48: sensor_3_kurtosis, Ranking: 1, Selected: True\n",
      "Feature index 49: sensor_3_25th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 50: sensor_3_75th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 51: sensor_3_ptp, Ranking: 25, Selected: False\n",
      "Feature index 52: sensor_3_sum_psd, Ranking: 24, Selected: False\n",
      "Feature index 53: sensor_3_mean_psd, Ranking: 81, Selected: False\n",
      "Feature index 54: sensor_3_max_psd, Ranking: 54, Selected: False\n",
      "Feature index 55: sensor_3_freq_at_max_psd, Ranking: 92, Selected: False\n",
      "Feature index 56: sensor_4_mean, Ranking: 96, Selected: False\n",
      "Feature index 57: sensor_4_std, Ranking: 1, Selected: True\n",
      "Feature index 58: sensor_4_min, Ranking: 18, Selected: False\n",
      "Feature index 59: sensor_4_max, Ranking: 45, Selected: False\n",
      "Feature index 60: sensor_4_median, Ranking: 37, Selected: False\n",
      "Feature index 61: sensor_4_skew, Ranking: 77, Selected: False\n",
      "Feature index 62: sensor_4_kurtosis, Ranking: 1, Selected: True\n",
      "Feature index 63: sensor_4_25th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 64: sensor_4_75th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 65: sensor_4_ptp, Ranking: 1, Selected: True\n",
      "Feature index 66: sensor_4_sum_psd, Ranking: 91, Selected: False\n",
      "Feature index 67: sensor_4_mean_psd, Ranking: 89, Selected: False\n",
      "Feature index 68: sensor_4_max_psd, Ranking: 53, Selected: False\n",
      "Feature index 69: sensor_4_freq_at_max_psd, Ranking: 70, Selected: False\n",
      "Feature index 70: sensor_5_mean, Ranking: 83, Selected: False\n",
      "Feature index 71: sensor_5_std, Ranking: 6, Selected: False\n",
      "Feature index 72: sensor_5_min, Ranking: 15, Selected: False\n",
      "Feature index 73: sensor_5_max, Ranking: 38, Selected: False\n",
      "Feature index 74: sensor_5_median, Ranking: 44, Selected: False\n",
      "Feature index 75: sensor_5_skew, Ranking: 23, Selected: False\n",
      "Feature index 76: sensor_5_kurtosis, Ranking: 1, Selected: True\n",
      "Feature index 77: sensor_5_25th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 78: sensor_5_75th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 79: sensor_5_ptp, Ranking: 16, Selected: False\n",
      "Feature index 80: sensor_5_sum_psd, Ranking: 88, Selected: False\n",
      "Feature index 81: sensor_5_mean_psd, Ranking: 86, Selected: False\n",
      "Feature index 82: sensor_5_max_psd, Ranking: 52, Selected: False\n",
      "Feature index 83: sensor_5_freq_at_max_psd, Ranking: 61, Selected: False\n",
      "Feature index 84: sensor_6_mean, Ranking: 63, Selected: False\n",
      "Feature index 85: sensor_6_std, Ranking: 1, Selected: True\n",
      "Feature index 86: sensor_6_min, Ranking: 27, Selected: False\n",
      "Feature index 87: sensor_6_max, Ranking: 62, Selected: False\n",
      "Feature index 88: sensor_6_median, Ranking: 20, Selected: False\n",
      "Feature index 89: sensor_6_skew, Ranking: 21, Selected: False\n",
      "Feature index 90: sensor_6_kurtosis, Ranking: 1, Selected: True\n",
      "Feature index 91: sensor_6_25th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 92: sensor_6_75th_percentile, Ranking: 12, Selected: False\n",
      "Feature index 93: sensor_6_ptp, Ranking: 3, Selected: False\n",
      "Feature index 94: sensor_6_sum_psd, Ranking: 58, Selected: False\n",
      "Feature index 95: sensor_6_mean_psd, Ranking: 71, Selected: False\n",
      "Feature index 96: sensor_6_max_psd, Ranking: 64, Selected: False\n",
      "Feature index 97: sensor_6_freq_at_max_psd, Ranking: 50, Selected: False\n",
      "Feature index 98: sensor_7_mean, Ranking: 82, Selected: False\n",
      "Feature index 99: sensor_7_std, Ranking: 5, Selected: False\n",
      "Feature index 100: sensor_7_min, Ranking: 10, Selected: False\n",
      "Feature index 101: sensor_7_max, Ranking: 1, Selected: True\n",
      "Feature index 102: sensor_7_median, Ranking: 73, Selected: False\n",
      "Feature index 103: sensor_7_skew, Ranking: 75, Selected: False\n",
      "Feature index 104: sensor_7_kurtosis, Ranking: 28, Selected: False\n",
      "Feature index 105: sensor_7_25th_percentile, Ranking: 78, Selected: False\n",
      "Feature index 106: sensor_7_75th_percentile, Ranking: 80, Selected: False\n",
      "Feature index 107: sensor_7_ptp, Ranking: 11, Selected: False\n",
      "Feature index 108: sensor_7_sum_psd, Ranking: 26, Selected: False\n",
      "Feature index 109: sensor_7_mean_psd, Ranking: 60, Selected: False\n",
      "Feature index 110: sensor_7_max_psd, Ranking: 68, Selected: False\n",
      "Feature index 111: sensor_7_freq_at_max_psd, Ranking: 1, Selected: True\n",
      "Feature index 112: sensor_8_mean, Ranking: 31, Selected: False\n",
      "Feature index 113: sensor_8_std, Ranking: 1, Selected: True\n",
      "Feature index 114: sensor_8_min, Ranking: 56, Selected: False\n",
      "Feature index 115: sensor_8_max, Ranking: 69, Selected: False\n",
      "Feature index 116: sensor_8_median, Ranking: 4, Selected: False\n",
      "Feature index 117: sensor_8_skew, Ranking: 30, Selected: False\n",
      "Feature index 118: sensor_8_kurtosis, Ranking: 79, Selected: False\n",
      "Feature index 119: sensor_8_25th_percentile, Ranking: 1, Selected: True\n",
      "Feature index 120: sensor_8_75th_percentile, Ranking: 59, Selected: False\n",
      "Feature index 121: sensor_8_ptp, Ranking: 47, Selected: False\n",
      "Feature index 122: sensor_8_sum_psd, Ranking: 76, Selected: False\n",
      "Feature index 123: sensor_8_mean_psd, Ranking: 48, Selected: False\n",
      "Feature index 124: sensor_8_max_psd, Ranking: 1, Selected: True\n",
      "Feature index 125: sensor_8_freq_at_max_psd, Ranking: 42, Selected: False\n",
      "Feature index 126: window_duration_mean, Ranking: 1, Selected: True\n"
     ]
    }
   ],
   "source": [
    "total_features = train_dataset.X.shape[1]\n",
    "num_sensors = (total_features - 1) // 14  # each sensor contributes 14 features\n",
    "base_features = [\"mean\", \"std\", \"min\", \"max\", \"median\", \"skew\", \"kurtosis\",\n",
    "                 \"25th_percentile\", \"75th_percentile\", \"ptp\", \"sum_psd\", \"mean_psd\",\n",
    "                 \"max_psd\", \"freq_at_max_psd\"]\n",
    "feature_mapping = {}\n",
    "idx = 0\n",
    "for sensor in range(num_sensors):\n",
    "    for feat in base_features:\n",
    "        feature_mapping[idx] = f\"sensor_{sensor}_{feat}\"\n",
    "        idx += 1\n",
    "feature_mapping[idx] = \"window_duration_mean\"\n",
    "\n",
    "for i in range(total_features):\n",
    "    print(f\"Feature index {i}: {feature_mapping[i]}, Ranking: {selector.ranking_[i]}, Selected: {selector.support_[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9568\n",
      "Precision: 0.9679\n",
      "Recall: 0.9031\n",
      "F1 Score: 0.9344\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      1937\n",
      "           1       0.97      0.90      0.93      1001\n",
      "\n",
      "    accuracy                           0.96      2938\n",
      "   macro avg       0.96      0.94      0.95      2938\n",
      "weighted avg       0.96      0.96      0.96      2938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = [False,  True, False, False, False, False,  True, False, False,\n",
    "        True, False, False, False, False, False, False, False, False,\n",
    "       False, False,  True,  True, False, False, False, False, False,\n",
    "       False, False,  True, False, False, False, False,  True,  True,\n",
    "        True,  True, False, False, False, False, False,  True, False,\n",
    "       False, False, False,  True,  True,  True, False, False, False,\n",
    "       False, False, False,  True, False, False, False, False,  True,\n",
    "        True,  True,  True, False, False, False, False, False, False,\n",
    "       False, False, False, False,  True,  True,  True, False, False,\n",
    "       False, False, False, False,  True, False, False, False, False,\n",
    "        True,  True, False, False, False, False, False, False, False,\n",
    "       False, False,  True, False, False, False, False, False, False,\n",
    "       False, False, False,  True, False,  True, False, False, False,\n",
    "       False, False,  True, False, False, False, False,  True, False,\n",
    "        True]\n",
    "\n",
    "X_train_selected = train_dataset.X[:, support]\n",
    "X_test_selected = test_dataset.X[:, support]\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.2,\n",
    "        max_depth=3,\n",
    "        min_samples_split=2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "ensemble_gb = BaggingClassifier(\n",
    "    estimator=gb,\n",
    "    n_estimators=5,\n",
    "    max_samples=0.9,\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the ensemble on the training set\n",
    "ensemble_gb.fit(X_train_selected, train_dataset.y)\n",
    "\n",
    "y_test = test_dataset.y\n",
    "y_test_pred = ensemble_gb.predict(X_test_selected)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
